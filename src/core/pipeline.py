#!/usr/bin/env python3
"""
æ•°æ®ç®¡é“æ¨¡å¼ - å°†å¤æ‚çš„æ•°æ®å¤„ç†åˆ†è§£ä¸ºç‹¬ç«‹çš„æ­¥éª¤
æé«˜ä»£ç å¯æµ‹è¯•æ€§å’Œå¯ç»´æŠ¤æ€§
"""

import asyncio
import logging
import time
from typing import Dict, List, Any, Optional, Callable, Tuple
from datetime import datetime
from dataclasses import dataclass, field
from enum import Enum

from core.exceptions import HedgeEngineError, classify_exception

logger = logging.getLogger(__name__)

# Export key classes for external use
__all__ = [
    'HedgePipeline',
    'PipelineContext',
    'PipelineStep',
    'StepResult',
    'StepStatus',
    'create_hedge_pipeline',
    'FetchPoolDataStep',
    'CalculateIdealHedgesStep',
    'FetchMarketDataStep',
    'CalculateOffsetsStep',
    'ApplyPredefinedOffsetStep',
    'DecideActionsStep',
    'ExecuteActionsStep',
    'logging_middleware',
    'timing_middleware',
    'error_collection_middleware'
]


class StepStatus(Enum):
    """æ­¥éª¤æ‰§è¡ŒçŠ¶æ€"""
    PENDING = "pending"
    RUNNING = "running"
    SUCCESS = "success"
    FAILED = "failed"
    SKIPPED = "skipped"


@dataclass
class StepResult:
    """æ­¥éª¤æ‰§è¡Œç»“æœ"""
    name: str
    status: StepStatus
    data: Any = None
    error: Optional[Exception] = None
    duration: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class PipelineContext:
    """ç®¡é“ä¸Šä¸‹æ–‡ - åœ¨æ­¥éª¤é—´ä¼ é€’æ•°æ®"""
    # è¾“å…¥æ•°æ®
    config: dict

    # ä¸­é—´ç»“æœå­˜å‚¨
    pool_data: Dict[str, Any] = field(default_factory=dict)
    ideal_hedges: Dict[str, float] = field(default_factory=dict)
    actual_positions: Dict[str, float] = field(default_factory=dict)
    prices: Dict[str, float] = field(default_factory=dict)
    offsets: Dict[str, Tuple[float, float]] = field(default_factory=dict)  # (offset, cost_basis)
    actions: List[Dict[str, Any]] = field(default_factory=list)

    # æ‰§è¡Œç»“æœ
    results: List[StepResult] = field(default_factory=list)

    # å…ƒæ•°æ®
    metadata: Dict[str, Any] = field(default_factory=dict)

    def add_result(self, result: StepResult):
        """æ·»åŠ æ­¥éª¤ç»“æœ"""
        self.results.append(result)
        if result.status == StepStatus.SUCCESS:
            logger.debug(f"Step '{result.name}' completed in {result.duration:.2f}s")
        elif result.status == StepStatus.FAILED:
            logger.error(f"Step '{result.name}' failed: {result.error}")


class PipelineStep:
    """ç®¡é“æ­¥éª¤åŸºç±»"""

    def __init__(
        self,
        name: str,
        required: bool = True,
        retry_times: int = 0,
        timeout: Optional[float] = None
    ):
        """
        Args:
            name: æ­¥éª¤åç§°
            required: æ˜¯å¦å¿…é¡»æˆåŠŸ
            retry_times: é‡è¯•æ¬¡æ•°
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.name = name
        self.required = required
        self.retry_times = retry_times
        self.timeout = timeout

    async def execute(self, context: PipelineContext) -> StepResult:
        """æ‰§è¡Œæ­¥éª¤"""
        start_time = time.time()

        for attempt in range(self.retry_times + 1):
            try:
                # è®¾ç½®è¶…æ—¶
                if self.timeout:
                    result = await asyncio.wait_for(
                        self._run(context),
                        timeout=self.timeout
                    )
                else:
                    result = await self._run(context)

                duration = time.time() - start_time
                return StepResult(
                    name=self.name,
                    status=StepStatus.SUCCESS,
                    data=result,
                    duration=duration
                )

            except asyncio.TimeoutError as e:
                if attempt < self.retry_times:
                    logger.warning(f"Step '{self.name}' timeout, retrying ({attempt + 1}/{self.retry_times})")
                    await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
                    continue

                return StepResult(
                    name=self.name,
                    status=StepStatus.FAILED,
                    error=e,
                    duration=time.time() - start_time
                )

            except Exception as e:
                if attempt < self.retry_times:
                    logger.warning(f"Step '{self.name}' failed, retrying ({attempt + 1}/{self.retry_times}): {e}")
                    await asyncio.sleep(2 ** attempt)
                    continue

                return StepResult(
                    name=self.name,
                    status=StepStatus.FAILED,
                    error=e,
                    duration=time.time() - start_time
                )

        # ä¸åº”è¯¥åˆ°è¾¾è¿™é‡Œ
        return StepResult(
            name=self.name,
            status=StepStatus.FAILED,
            error=RuntimeError("Unexpected execution path"),
            duration=time.time() - start_time
        )

    async def _run(self, context: PipelineContext) -> Any:
        """å­ç±»éœ€è¦å®ç°çš„å®é™…æ‰§è¡Œé€»è¾‘"""
        raise NotImplementedError


class HedgePipeline:
    """
    å¯¹å†²å¤„ç†ç®¡é“

    å°†å¤æ‚çš„å¯¹å†²é€»è¾‘åˆ†è§£ä¸ºç‹¬ç«‹çš„æ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤ä¸“æ³¨äºå•ä¸€èŒè´£
    """

    def __init__(self):
        self.steps: List[PipelineStep] = []
        self.middlewares: List[Callable] = []

    def add_step(self, step: PipelineStep):
        """æ·»åŠ å¤„ç†æ­¥éª¤"""
        self.steps.append(step)
        return self

    def add_middleware(self, middleware: Callable):
        """æ·»åŠ ä¸­é—´ä»¶ï¼ˆå¦‚æ—¥å¿—ã€ç¼“å­˜ç­‰ï¼‰"""
        self.middlewares.append(middleware)
        return self

    async def execute(self, context: PipelineContext) -> PipelineContext:
        """æ‰§è¡Œç®¡é“"""
        logger.info(f"Starting pipeline with {len(self.steps)} steps")

        # æ‰§è¡Œå‰ç½®ä¸­é—´ä»¶
        for middleware in self.middlewares:
            if asyncio.iscoroutinefunction(middleware):
                await middleware(context, "before")
            else:
                middleware(context, "before")

        # æ‰§è¡Œå„ä¸ªæ­¥éª¤
        for step in self.steps:
            logger.info(f"Executing step: {step.name}")

            result = await step.execute(context)
            context.add_result(result)

            # å¦‚æœæ˜¯å¿…éœ€æ­¥éª¤ä¸”å¤±è´¥ï¼Œåœæ­¢ç®¡é“
            if step.required and result.status == StepStatus.FAILED:
                logger.error(f"Required step '{step.name}' failed, stopping pipeline")
                break

        # æ‰§è¡Œåç½®ä¸­é—´ä»¶
        for middleware in self.middlewares:
            if asyncio.iscoroutinefunction(middleware):
                await middleware(context, "after")
            else:
                middleware(context, "after")

        # è®°å½•æ‰§è¡Œç»Ÿè®¡
        self._log_statistics(context)

        return context

    def _log_statistics(self, context: PipelineContext):
        """è®°å½•æ‰§è¡Œç»Ÿè®¡"""
        total_duration = sum(r.duration for r in context.results)
        success_count = sum(1 for r in context.results if r.status == StepStatus.SUCCESS)
        failed_count = sum(1 for r in context.results if r.status == StepStatus.FAILED)

        logger.info(f"Pipeline completed: {success_count} success, {failed_count} failed, "
                   f"total duration: {total_duration:.2f}s")


# ==================== å…·ä½“æ­¥éª¤å®ç° ====================

class FetchPoolDataStep(PipelineStep):
    """è·å–æ± å­æ•°æ®æ­¥éª¤"""

    def __init__(self, pool_calculators: dict):
        super().__init__(
            name="FetchPoolData",
            required=True,
            retry_times=2,
            timeout=30
        )
        self.pool_calculators = pool_calculators

    async def _run(self, context: PipelineContext) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰æ± å­æ•°æ®"""
        pool_data = {}

        logger.info("=" * 50)
        logger.info("ğŸ“Š FETCHING POOL DATA")
        logger.info("=" * 50)

        for pool_type, calculator in self.pool_calculators.items():
            amount = context.config.get(f"{pool_type}_amount", 0)
            if amount > 0:
                logger.info(f"ğŸŠ {pool_type.upper()} Pool: Amount = {amount:,.2f}")
                positions = await calculator(amount)
                pool_data[pool_type] = positions

                # è¯¦ç»†æ˜¾ç¤ºæ¯ä¸ªæ± å­çš„æŒä»“
                logger.info(f"  â””â”€ Positions in {pool_type.upper()}:")
                for symbol, data in positions.items():
                    amount_value = data["amount"] if isinstance(data, dict) else data
                    logger.info(f"     â€¢ {symbol}: {amount_value:,.4f}")

        context.pool_data = pool_data
        logger.info(f"âœ… Fetched data from {len(pool_data)} pools")
        return pool_data


class CalculateIdealHedgesStep(PipelineStep):
    """è®¡ç®—ç†æƒ³å¯¹å†²é‡æ­¥éª¤"""

    def __init__(self):
        super().__init__(
            name="CalculateIdealHedges",
            required=True,
            retry_times=0,
            timeout=10
        )

    async def _run(self, context: PipelineContext) -> Dict[str, float]:
        """åˆå¹¶è®¡ç®—ç†æƒ³å¯¹å†²é‡"""
        merged_hedges = {}

        logger.info("=" * 50)
        logger.info("ğŸ¯ CALCULATING IDEAL HEDGES")
        logger.info("=" * 50)

        # è¯¦ç»†æ˜¾ç¤ºæ¯ä¸ªæ± å­çš„è´¡çŒ®
        for pool_type, positions in context.pool_data.items():
            logger.info(f"ğŸ“ˆ {pool_type.upper()} Pool Contributions:")
            for symbol, data in positions.items():
                # è½¬æ¢ç¬¦å·ï¼ˆWBTC -> BTCï¼‰
                exchange_symbol = "BTC" if symbol == "WBTC" else symbol

                # ç´¯åŠ å¯¹å†²é‡ï¼ˆè´Ÿæ•°è¡¨ç¤ºåšç©ºï¼‰
                if exchange_symbol not in merged_hedges:
                    merged_hedges[exchange_symbol] = 0

                # ä»dataä¸­æå–amountï¼ˆæ ¹æ®å®é™…æ•°æ®ç»“æ„ï¼‰
                amount = data["amount"] if isinstance(data, dict) else data
                hedge_amount = -amount  # è´Ÿæ•°è¡¨ç¤ºåšç©º
                merged_hedges[exchange_symbol] += hedge_amount

                logger.info(f"  â€¢ {symbol} â†’ {exchange_symbol}: {hedge_amount:+.4f} (short)")

        # æ˜¾ç¤ºæœ€ç»ˆçš„åˆå¹¶ç»“æœ
        logger.info("ğŸ“Š MERGED IDEAL POSITIONS (Negative = Short):")
        for symbol, amount in sorted(merged_hedges.items()):
            logger.info(f"  ğŸ’¹ {symbol}: {amount:+.4f}")

        context.ideal_hedges = merged_hedges
        logger.info(f"âœ… Calculated hedges for {len(merged_hedges)} symbols")
        return merged_hedges


class FetchMarketDataStep(PipelineStep):
    """è·å–å¸‚åœºæ•°æ®æ­¥éª¤ï¼ˆä»·æ ¼å’ŒæŒä»“ï¼‰"""

    def __init__(self, exchange):
        super().__init__(
            name="FetchMarketData",
            required=True,
            retry_times=2,
            timeout=30
        )
        self.exchange = exchange

    async def _run(self, context: PipelineContext) -> Dict[str, Any]:
        """å¹¶å‘è·å–ä»·æ ¼å’ŒæŒä»“"""
        symbols = list(context.ideal_hedges.keys())

        logger.info("=" * 50)
        logger.info("ğŸ’¹ FETCHING MARKET DATA")
        logger.info("=" * 50)

        # å¹¶å‘è·å–ä»·æ ¼
        price_tasks = {
            symbol: self.exchange.get_price(symbol)
            for symbol in symbols
        }

        # å¹¶å‘è·å–æŒä»“
        position_tasks = {
            symbol: self.exchange.get_position(symbol)
            for symbol in symbols
        }

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        prices_results = await asyncio.gather(*price_tasks.values(), return_exceptions=True)
        positions_results = await asyncio.gather(*position_tasks.values(), return_exceptions=True)

        # å¤„ç†ç»“æœ
        prices = {}
        positions = {}

        logger.info("ğŸ“ˆ CURRENT PRICES:")
        for symbol, price in zip(price_tasks.keys(), prices_results):
            if isinstance(price, Exception):
                logger.error(f"  âŒ {symbol}: Failed to get price - {price}")
            else:
                prices[symbol] = price
                logger.info(f"  ğŸ’µ {symbol}: ${price:,.2f}")

        logger.info("ğŸ“Š ACTUAL POSITIONS (Exchange + Initial Offset):")
        for symbol, position in zip(position_tasks.keys(), positions_results):
            if isinstance(position, Exception):
                logger.error(f"  âŒ {symbol}: Failed to get position - {position}")
                positions[symbol] = 0.0  # é»˜è®¤ä¸º0
            else:
                # åŠ ä¸Šåˆå§‹åç§»é‡
                initial_offset = context.config.get("initial_offset", {}).get(symbol, 0.0)
                total_position = position + initial_offset
                positions[symbol] = total_position

                if initial_offset != 0:
                    logger.info(f"  ğŸ“ {symbol}: {total_position:+.4f} "
                               f"(Exchange: {position:+.4f}, Initial: {initial_offset:+.4f})")
                else:
                    logger.info(f"  ğŸ“ {symbol}: {total_position:+.4f}")

        context.prices = prices
        context.actual_positions = positions

        logger.info(f"âœ… Fetched market data for {len(prices)} symbols")
        return {"prices": prices, "positions": positions}


class CalculateOffsetsStep(PipelineStep):
    """è®¡ç®—åç§»é‡æ­¥éª¤"""

    def __init__(self, offset_calculator, state_manager):
        super().__init__(
            name="CalculateOffsets",
            required=True,
            retry_times=0,
            timeout=10
        )
        self.offset_calculator = offset_calculator
        self.state_manager = state_manager

    async def _run(self, context: PipelineContext) -> Dict[str, Tuple[float, float]]:
        """è®¡ç®—æ‰€æœ‰å¸ç§çš„åç§»é‡å’Œæˆæœ¬åŸºç¡€"""
        offsets = {}

        logger.info("=" * 50)
        logger.info("ğŸ” CALCULATING OFFSETS AND COST BASIS")
        logger.info("=" * 50)

        for symbol in context.ideal_hedges.keys():
            if symbol not in context.prices:
                logger.warning(f"âš ï¸ Skipping {symbol} due to missing price")
                continue

            # è·å–å†å²çŠ¶æ€
            state = await self.state_manager.get_symbol_state(symbol)
            old_offset = state.get("offset", 0.0)
            old_cost = state.get("cost_basis", 0.0)
            old_actual_pos = state.get("last_actual_position", None)

            # è®¡ç®—æ–°çš„åç§»å’Œæˆæœ¬
            ideal_pos = context.ideal_hedges[symbol]
            actual_pos = context.actual_positions.get(symbol, 0.0)
            current_price = context.prices[symbol]

            new_offset, new_cost = self.offset_calculator(
                ideal_pos, actual_pos, current_price, old_offset, old_cost
            )

            offsets[symbol] = (new_offset, new_cost)

            # è®¡ç®—USDä»·å€¼
            offset_usd = abs(new_offset) * current_price

            # æ£€æµ‹positionå˜åŒ–ï¼ˆè¯´æ˜æœ‰æˆäº¤æˆ–æ‰‹åŠ¨è°ƒä»“ï¼‰
            if old_actual_pos is not None:  # åªæœ‰æœ‰å†å²è®°å½•æ—¶æ‰æ£€æµ‹
                position_change = abs(actual_pos - old_actual_pos)
                if position_change > 0.0001:  # é˜²æ­¢æµ®ç‚¹è¯¯å·®
                    logger.info(f"  âš¡ {symbol}: Position changed from {old_actual_pos:+.4f} to {actual_pos:+.4f} (Î”{actual_pos - old_actual_pos:+.4f})")
                    # è®°å½•æˆäº¤æ—¶é—´
                    await self.state_manager.update_symbol_state(symbol, {
                        "last_fill_time": datetime.now().isoformat()
                    })

            # è¯¦ç»†æ—¥å¿—è¾“å‡º
            logger.info(f"ğŸ“Š {symbol}:")
            logger.info(f"  â”œâ”€ Ideal Position: {ideal_pos:+.4f}")
            logger.info(f"  â”œâ”€ Actual Position: {actual_pos:+.4f}")
            logger.info(f"  â”œâ”€ Offset: {new_offset:+.4f} ({offset_usd:.2f} USD)")
            logger.info(f"  â”œâ”€ Cost Basis: ${new_cost:.2f} (Previous: ${old_cost:.2f})")

            # æ˜¾ç¤ºåç§»æ–¹å‘
            if new_offset > 0:
                logger.info(f"  â””â”€ Status: ğŸ”´ LONG exposure (Need to SELL {abs(new_offset):.4f})")
            elif new_offset < 0:
                logger.info(f"  â””â”€ Status: ğŸŸ¢ SHORT exposure (Need to BUY {abs(new_offset):.4f})")
            else:
                logger.info(f"  â””â”€ Status: âœ… BALANCED")

            # æ›´æ–°çŠ¶æ€ï¼ˆåŒ…æ‹¬actual positionï¼‰
            await self.state_manager.update_symbol_state(symbol, {
                "offset": new_offset,
                "cost_basis": new_cost,
                "last_actual_position": actual_pos
            })

        context.offsets = offsets
        logger.info(f"âœ… Calculated offsets for {len(offsets)} symbols")
        return offsets


class ApplyPredefinedOffsetStep(PipelineStep):
    """åº”ç”¨é¢„è®¾åç§»é‡æ­¥éª¤ - å¤„ç†å¤–éƒ¨å¯¹å†²è°ƒæ•´"""

    def __init__(self):
        super().__init__(
            name="ApplyPredefinedOffset",
            required=False,  # éå¿…éœ€ï¼Œå¦‚æœæ²¡æœ‰é…ç½®å°±è·³è¿‡
            retry_times=0,
            timeout=5
        )

    async def _run(self, context: PipelineContext) -> Dict[str, Tuple[float, float]]:
        """åº”ç”¨é¢„è®¾çš„åç§»é‡è°ƒæ•´ï¼ˆç”¨äºå¤–éƒ¨å¯¹å†²ï¼‰"""
        predefined = context.config.get("predefined_offset", {})

        if not predefined:
            logger.info("âœ… No predefined offset configured, skipping")
            return context.offsets

        logger.info("=" * 50)
        logger.info("ğŸ”§ APPLYING PREDEFINED OFFSETS")
        logger.info("=" * 50)

        # ä¿å­˜åŸå§‹offsetç”¨äºå¯¹æ¯”å’Œè°ƒè¯•
        context.metadata["raw_offsets"] = context.offsets.copy()

        adjusted_count = 0
        for symbol, adjustment in predefined.items():
            if symbol in context.offsets:
                old_offset, cost_basis = context.offsets[symbol]
                new_offset = old_offset - adjustment

                # è®¡ç®—USDä»·å€¼
                if symbol in context.prices:
                    old_offset_usd = abs(old_offset) * context.prices[symbol]
                    new_offset_usd = abs(new_offset) * context.prices[symbol]

                    logger.info(f"ğŸ“Š {symbol}:")
                    logger.info(f"  â”œâ”€ Raw Offset: {old_offset:+.6f} (${old_offset_usd:.2f})")
                    logger.info(f"  â”œâ”€ Adjustment: {adjustment:+.6f} (external hedge)")
                    logger.info(f"  â””â”€ Final Offset: {new_offset:+.6f} (${new_offset_usd:.2f})")

                    # æ›´æ–°context
                    context.offsets[symbol] = (new_offset, cost_basis)
                    adjusted_count += 1
            else:
                logger.warning(f"âš ï¸ Symbol {symbol} has predefined offset but no calculated offset, skipping")

        logger.info(f"âœ… Applied predefined offsets for {adjusted_count} symbols")
        return context.offsets


class DecideActionsStep(PipelineStep):
    """å†³ç­–æ­¥éª¤ - ä½¿ç”¨å†³ç­–å¼•æ“å†³å®šéœ€è¦æ‰§è¡Œçš„æ“ä½œ"""

    def __init__(self, decision_engine):
        super().__init__(
            name="DecideActions",
            required=True,
            retry_times=0,
            timeout=10
        )
        self.decision_engine = decision_engine

    async def _run(self, context: PipelineContext) -> List[Any]:
        """æ ¹æ®å¸‚åœºæ•°æ®å†³å®šæ“ä½œ"""
        logger.info("=" * 50)
        logger.info("ğŸ¤” DECISION ENGINE - EVALUATING ACTIONS")
        logger.info("=" * 50)

        # å‡†å¤‡å†³ç­–æ•°æ®
        market_data = {}

        # æ˜¾ç¤ºé˜ˆå€¼é…ç½®
        threshold_min = self.decision_engine.threshold_min_usd
        threshold_max = self.decision_engine.threshold_max_usd
        threshold_step = self.decision_engine.threshold_step_usd
        logger.info(f"âš¡ Thresholds: ${threshold_min:.2f} - ${threshold_max:.2f} (Step: ${threshold_step:.2f})")

        for symbol, (offset, cost_basis) in context.offsets.items():
            if symbol not in context.prices:
                logger.warning(f"âš ï¸ Skipping {symbol} - no price data")
                continue

            current_price = context.prices[symbol]
            offset_usd = abs(offset) * current_price

            market_data[symbol] = {
                "offset": offset,
                "cost_basis": cost_basis,
                "current_price": current_price,
                "offset_usd": offset_usd
            }

            # æ˜¾ç¤ºå¸ç§è¯„ä¼°
            zone = self.decision_engine.get_zone(offset_usd)
            logger.info(f"ğŸ¯ {symbol}: Offset ${offset_usd:.2f} â†’ Zone {zone}")

        # æ‰¹é‡å†³ç­–
        actions = await self.decision_engine.batch_decide(market_data)

        # æ˜¾ç¤ºå†³ç­–ç»“æœ
        logger.info("ğŸ“‹ DECISIONS:")
        action_counts = {}
        for action in actions:
            action_type = action.type.value
            action_counts[action_type] = action_counts.get(action_type, 0) + 1

            # æ ¹æ®ä¸åŒæ“ä½œç±»å‹æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            if action.type.value == "place_limit_order":
                logger.info(f"  ğŸ“ {action.symbol}: PLACE LIMIT {action.side.upper()} "
                           f"{action.size:.4f} @ ${action.price:.2f} - {action.reason}")
            elif action.type.value == "place_market_order":
                logger.info(f"  ğŸš¨ {action.symbol}: PLACE MARKET {action.side.upper()} "
                           f"{action.size:.4f} - {action.reason}")
            elif action.type.value == "cancel_order":
                logger.info(f"  âŒ {action.symbol}: CANCEL ORDER {action.order_id} - {action.reason}")
            elif action.type.value == "alert":
                logger.info(f"  âš ï¸ {action.symbol}: ALERT - {action.reason}")
            elif action.type.value == "no_action":
                logger.debug(f"  âœ… {action.symbol}: NO ACTION - {action.reason}")

        # æ˜¾ç¤ºæ±‡æ€»
        logger.info(f"ğŸ“Š Summary: {action_counts}")

        context.actions = actions
        logger.info(f"âœ… Decided on {len(actions)} actions")
        return actions


class ExecuteActionsStep(PipelineStep):
    """æ‰§è¡Œæ“ä½œæ­¥éª¤ - ä½¿ç”¨æ“ä½œæ‰§è¡Œå™¨æ‰§è¡Œæ‰€æœ‰å†³ç­–"""

    def __init__(self, action_executor):
        super().__init__(
            name="ExecuteActions",
            required=False,  # æ‰§è¡Œå¤±è´¥ä¸åœæ­¢ç®¡é“
            retry_times=1,
            timeout=60
        )
        self.action_executor = action_executor

    async def _run(self, context: PipelineContext) -> List[Any]:
        """æ‰§è¡Œæ‰€æœ‰å†³å®šçš„æ“ä½œ"""
        if not context.actions:
            logger.info("âœ… No actions to execute")
            return []

        logger.info("=" * 50)
        logger.info("âš¡ EXECUTING ACTIONS")
        logger.info("=" * 50)

        logger.info(f"ğŸ¯ Executing {len(context.actions)} actions...")

        # ä½¿ç”¨æ‰§è¡Œå™¨æ‰¹é‡æ‰§è¡Œ
        # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ä¸²è¡Œæ‰§è¡Œä»¥é¿å…ç«æ€æ¡ä»¶
        results = await self.action_executor.batch_execute(
            context.actions,
            parallel=False
        )

        # æ˜¾ç¤ºæ‰§è¡Œç»“æœ
        logger.info("ğŸ“Š EXECUTION RESULTS:")
        for i, result in enumerate(results, 1):
            action = result.action
            if result.success:
                if action.type.value == "place_limit_order":
                    logger.info(f"  âœ… [{i}] {action.symbol}: Limit order placed - "
                               f"{action.side.upper()} {action.size:.4f} @ ${action.price:.2f} "
                               f"(Order ID: {result.result})")
                elif action.type.value == "place_market_order":
                    logger.info(f"  âœ… [{i}] {action.symbol}: Market order executed - "
                               f"{action.side.upper()} {action.size:.4f} "
                               f"(Order ID: {result.result})")
                elif action.type.value == "cancel_order":
                    logger.info(f"  âœ… [{i}] {action.symbol}: Order cancelled - ID: {action.order_id}")
                elif action.type.value == "alert":
                    logger.info(f"  âœ… [{i}] {action.symbol}: Alert sent - {action.reason}")
                elif action.type.value == "no_action":
                    logger.debug(f"  âœ… [{i}] {action.symbol}: No action taken")
            else:
                logger.error(f"  âŒ [{i}] {action.symbol}: Failed to {action.type.value} - "
                            f"Error: {result.error}")

        # ç»Ÿè®¡æ‰§è¡Œç»“æœ
        success_count = sum(1 for r in results if r.success)
        failed_count = len(results) - success_count

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = self.action_executor.get_stats()
        logger.info("ğŸ“ˆ EXECUTION STATISTICS:")
        logger.info(f"  â€¢ Total Actions: {len(results)}")
        logger.info(f"  â€¢ Successful: {success_count}")
        logger.info(f"  â€¢ Failed: {failed_count}")
        logger.info(f"  â€¢ Success Rate: {stats.get('success_rate', 0)*100:.1f}%")

        # æŒ‰ç±»å‹æ˜¾ç¤ºç»Ÿè®¡
        if stats.get('by_type'):
            logger.info("  â€¢ By Type:")
            for action_type, type_stats in stats['by_type'].items():
                logger.info(f"    - {action_type}: {type_stats['success']} success, "
                           f"{type_stats['failed']} failed")

        # å°†ç»“æœå­˜å…¥ä¸Šä¸‹æ–‡
        context.metadata["execution_results"] = results
        context.metadata["execution_stats"] = stats

        logger.info(f"âœ… Execution complete: {success_count}/{len(results)} successful")
        return results


# ==================== ç®¡é“å·¥å‚ ====================

def create_hedge_pipeline(
    pool_calculators: Dict[str, Any],
    exchange,
    state_manager,
    offset_calculator,
    decision_engine,
    action_executor
) -> HedgePipeline:
    """
    åˆ›å»ºå®Œæ•´çš„å¯¹å†²å¤„ç†ç®¡é“

    Args:
        pool_calculators: æ± å­è®¡ç®—å™¨å­—å…¸
        exchange: äº¤æ˜“æ‰€æ¥å£
        state_manager: çŠ¶æ€ç®¡ç†å™¨
        offset_calculator: åç§»è®¡ç®—å‡½æ•°
        decision_engine: å†³ç­–å¼•æ“
        action_executor: æ“ä½œæ‰§è¡Œå™¨

    Returns:
        é…ç½®å¥½çš„ç®¡é“å®ä¾‹
    """
    pipeline = HedgePipeline()

    # æ·»åŠ ä¸­é—´ä»¶
    pipeline.add_middleware(logging_middleware)
    pipeline.add_middleware(timing_middleware)
    pipeline.add_middleware(error_collection_middleware)

    # æ·»åŠ å¤„ç†æ­¥éª¤
    pipeline.add_step(FetchPoolDataStep(pool_calculators))
    pipeline.add_step(CalculateIdealHedgesStep())
    pipeline.add_step(FetchMarketDataStep(exchange))
    pipeline.add_step(CalculateOffsetsStep(offset_calculator, state_manager))
    pipeline.add_step(ApplyPredefinedOffsetStep())  # åº”ç”¨å¤–éƒ¨å¯¹å†²è°ƒæ•´
    pipeline.add_step(DecideActionsStep(decision_engine))
    pipeline.add_step(ExecuteActionsStep(action_executor))

    return pipeline


# ==================== ä¸­é—´ä»¶ ====================

async def logging_middleware(context: PipelineContext, phase: str):
    """æ—¥å¿—ä¸­é—´ä»¶ï¼ˆè‡ªåŠ¨é®è”½æ•æ„Ÿä¿¡æ¯ï¼‰"""
    if phase == "before":
        from utils.logging_utils import mask_sensitive_data
        masked_config = mask_sensitive_data(context.config)
        logger.debug(f"Pipeline starting with config: {masked_config}")
    elif phase == "after":
        success_count = sum(1 for r in context.results if r.status == StepStatus.SUCCESS)
        logger.info(f"Pipeline completed with {success_count}/{len(context.results)} successful steps")


async def timing_middleware(context: PipelineContext, phase: str):
    """è®¡æ—¶ä¸­é—´ä»¶"""
    if phase == "before":
        context.metadata["start_time"] = time.time()
    elif phase == "after":
        duration = time.time() - context.metadata.get("start_time", 0)
        context.metadata["total_duration"] = duration
        logger.info(f"Pipeline total execution time: {duration:.2f}s")


def error_collection_middleware(context: PipelineContext, phase: str):
    """é”™è¯¯æ”¶é›†ä¸­é—´ä»¶"""
    if phase == "after":
        errors = [r for r in context.results if r.status == StepStatus.FAILED]
        if errors:
            context.metadata["errors"] = [
                {
                    "step": r.name,
                    "error": str(r.error),
                    "timestamp": r.timestamp.isoformat()
                }
                for r in errors
            ]
            logger.warning(f"Pipeline completed with {len(errors)} errors")