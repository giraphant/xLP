#!/usr/bin/env python3
"""
å¯¹å†²å¼•æ“æ ¸å¿ƒæ¨¡å—
è´Ÿè´£è®¡ç®—åç§»ã€åˆ¤æ–­åŒºé—´ã€æ‰§è¡Œå¹³ä»“é€»è¾‘
"""

import json
import asyncio
import logging
import time
from datetime import datetime
from pathlib import Path

# å¯¼å…¥æœ¬åœ°æ¨¡å—
from exchanges.interface import create_exchange
from notifications.pushover import Notifier
from core.offset_tracker import calculate_offset_and_cost
from core.state_manager import StateManager
from core.exceptions import HedgeEngineError, InvalidConfigError
from core.pipeline import PipelineContext, create_hedge_pipeline
from core.decision_engine import DecisionEngine
from core.action_executor import ActionExecutor
from utils.circuit_breaker import CircuitBreakerManager
from utils.config_validator import HedgeConfig, ValidationError
from monitoring.metrics import MetricsCollector
from pools import jlp, alp

logger = logging.getLogger(__name__)


class HedgeEngine:
    def __init__(self, config_path: str = "config.json"):
        self.config_path = Path(config_path)

        # ä½¿ç”¨æ–°çš„é…ç½®éªŒè¯å™¨åŠ è½½é…ç½®
        try:
            self.validated_config = HedgeConfig.from_env_and_file(self.config_path)
            self.config = self.validated_config.to_dict()  # å…¼å®¹æ—§ä»£ç 
            logger.info(self.validated_config.get_summary())
        except ValidationError as e:
            logger.critical(f"Configuration validation failed: {e}")
            raise InvalidConfigError("config", str(e), "Valid configuration required")

        # åˆå§‹åŒ–çŠ¶æ€ç®¡ç†å™¨ï¼ˆå†…å­˜æ¨¡å¼ï¼‰
        self.state_manager = StateManager()

        # åˆå§‹åŒ–ç†”æ–­å™¨ç®¡ç†å™¨
        self.circuit_manager = CircuitBreakerManager()

        # åˆå§‹åŒ–æŒ‡æ ‡æ”¶é›†å™¨
        self.metrics = MetricsCollector()

        # åˆå§‹åŒ–äº¤æ˜“æ‰€å’Œé€šçŸ¥å™¨
        self.exchange = create_exchange(self.config["exchange"])
        self.notifier = Notifier(self.config["pushover"])

        # åˆå§‹åŒ–å†³ç­–å¼•æ“
        self.decision_engine = DecisionEngine(self.config, self.state_manager)

        # åˆå§‹åŒ–æ“ä½œæ‰§è¡Œå™¨
        self.action_executor = ActionExecutor(
            exchange=self.exchange,
            state_manager=self.state_manager,
            notifier=self.notifier,
            metrics_collector=self.metrics,
            circuit_manager=self.circuit_manager
        )

        # åˆ›å»ºå®Œæ•´çš„æ•°æ®å¤„ç†ç®¡é“
        self.pipeline = self._create_full_pipeline()

    def _create_full_pipeline(self):
        """åˆ›å»ºå®Œæ•´çš„æ•°æ®å¤„ç†ç®¡é“"""
        # å‡†å¤‡æ± å­è®¡ç®—å™¨
        pool_calculators = {
            "jlp": jlp.calculate_hedge,
            "alp": alp.calculate_hedge
        }

        # ä½¿ç”¨å·¥å‚å‡½æ•°åˆ›å»ºç®¡é“
        return create_hedge_pipeline(
            pool_calculators=pool_calculators,
            exchange=self.exchange,
            state_manager=self.state_manager,
            offset_calculator=calculate_offset_and_cost,
            decision_engine=self.decision_engine,
            action_executor=self.action_executor
        )

    async def run_once_pipeline(self):
        """ä½¿ç”¨ç®¡é“æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„å¯¹å†²æ£€æŸ¥å¾ªç¯"""
        start_time = time.time()
        logger.info(f"{'='*70}")
        logger.info(f"ğŸš€ HEDGE ENGINE PIPELINE - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"{'='*70}")

        try:
            # å‡†å¤‡ç®¡é“ä¸Šä¸‹æ–‡
            context = PipelineContext(
                config={
                    **self.config,
                    "jlp": {"amount": self.config["jlp_amount"]},
                    "alp": {"amount": self.config["alp_amount"]}
                }
            )

            # ä¸º reporting æä¾› state_manager
            context.metadata["state_manager"] = self.state_manager

            # æ‰§è¡Œç®¡é“
            context = await self.pipeline.execute(context)

            # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šï¼ˆå¦‚æœå¯ç”¨ï¼‰
            import os
            if os.getenv("ENABLE_DETAILED_REPORTS", "true").lower() in ("true", "1", "yes"):
                from monitoring.reports import generate_position_report
                await generate_position_report(context, self.state_manager)

            # å¤„ç†ç®¡é“ç»“æœ
            if context.results:
                success_count = sum(1 for r in context.results if r.status.value == "success")
                failed_count = sum(1 for r in context.results if r.status.value == "failed")

                # æ£€æŸ¥æ˜¯å¦æœ‰å…³é”®æ­¥éª¤å¤±è´¥
                critical_failures = [
                    r for r in context.results
                    if r.status.value == "failed" and r.name in ["FetchPoolData", "CalculateIdealHedges"]
                ]

                if critical_failures:
                    logger.error(f"âŒ Critical steps failed: {[f.name for f in critical_failures]}")
                    raise HedgeEngineError("Critical pipeline steps failed")

                # ç”Ÿæˆæœ€ç»ˆæ‘˜è¦æŠ¥å‘Š
                logger.info("=" * 70)
                logger.info("ğŸ“Š PIPELINE EXECUTION SUMMARY")
                logger.info("=" * 70)

                # æ˜¾ç¤ºå„æ­¥éª¤çŠ¶æ€
                logger.info("ğŸ“ˆ Step Results:")
                for result in context.results:
                    status_icon = "âœ…" if result.status.value == "success" else "âŒ"
                    logger.info(f"  {status_icon} {result.name}: {result.status.value} ({result.duration:.2f}s)")

                # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
                if context.offsets:
                    logger.info("ğŸ’° Position Summary:")
                    total_offset_usd = 0
                    for symbol, (offset, cost_basis) in context.offsets.items():
                        if symbol in context.prices:
                            offset_usd = abs(offset) * context.prices[symbol]
                            total_offset_usd += offset_usd
                            status = "ğŸ”´ LONG" if offset > 0 else ("ğŸŸ¢ SHORT" if offset < 0 else "âœ… BALANCED")
                            logger.info(f"  â€¢ {symbol}: {status} ${offset_usd:.2f} (Offset: {offset:+.4f})")
                    logger.info(f"  ğŸ“Š Total Exposure: ${total_offset_usd:.2f}")

                # æ˜¾ç¤ºæ‰§è¡Œç»“æœ
                if context.metadata.get("execution_results"):
                    exec_results = context.metadata["execution_results"]
                    exec_success = sum(1 for r in exec_results if r.success)
                    logger.info(f"âš¡ Actions Executed: {exec_success}/{len(exec_results)} successful")

                logger.info(f"â±ï¸ Total Time: {success_count} steps completed in {time.time() - start_time:.2f}s")

            # æ›´æ–°å…ƒæ•°æ®
            await self.state_manager.update_metadata({
                "last_check": datetime.now().isoformat(),
                "total_runs": (await self.state_manager.get_metadata()).get("total_runs", 0) + 1
            })

            # æ¸…ç†è¶…æ—¶çš„è®¢å•ç›‘æ§
            await self.state_manager.cleanup_stale_orders()

            # æ¸…ç†ç©ºé—²çš„ç†”æ–­å™¨
            self.circuit_manager.cleanup_idle()

            # è®°å½•å¤„ç†æ—¶é—´æŒ‡æ ‡
            processing_time = time.time() - start_time
            await self.metrics.record_processing("pipeline_run", processing_time)

            # å®šæœŸå¯¼å‡ºæŒ‡æ ‡æ‘˜è¦ï¼ˆæ¯10æ¬¡è¿è¡Œï¼‰
            total_runs = (await self.state_manager.get_metadata()).get("total_runs", 0)
            if total_runs % 10 == 0:
                summary = await self.metrics.export_summary()
                logger.info(f"Metrics Summary: {json.dumps(summary, indent=2)}")

            logger.info("=" * 70)
            logger.info(f"âœ… PIPELINE COMPLETED - Duration: {processing_time:.2f}s")
            logger.info("=" * 70)

        except Exception as e:
            logger.error(f"Pipeline execution error: {e}")
            # è®°å½•é”™è¯¯æŒ‡æ ‡
            self.metrics.record_error(type(e).__name__, str(e))

            # è®°å½•æœ€åçš„é”™è¯¯
            await self.state_manager.update_metadata({
                "last_error": str(e),
                "last_error_time": datetime.now().isoformat()
            })
            raise

    async def run_once(self):
        """æ‰§è¡Œä¸€æ¬¡æ£€æŸ¥å¾ªç¯ - ä½¿ç”¨æ•°æ®ç®¡é“æ¶æ„"""
        return await self.run_once_pipeline()


async def main():
    """æµ‹è¯•ä¸»å‡½æ•°"""
    engine = HedgeEngine()
    await engine.run_once()


if __name__ == "__main__":
    asyncio.run(main())
