#!/usr/bin/env python3
"""
å¯¹å†²å¼•æ“æ ¸å¿ƒæ¨¡å—
è´Ÿè´£è®¡ç®—åç§»ã€åˆ¤æ–­åŒºé—´ã€æ‰§è¡Œå¹³ä»“é€»è¾‘
"""

import json
import asyncio
import logging
import time
from datetime import datetime
from pathlib import Path

# å¯¼å…¥æœ¬åœ°æ¨¡å—
from exchanges import create_exchange
from utils.notifier import Notifier
from core.offset_tracker import calculate_offset_and_cost
from core.state_manager import StateManager
from core.exceptions import HedgeEngineError, InvalidConfigError
from core.pipeline import PipelineContext, create_hedge_pipeline
from core.decision_engine import DecisionEngine
from core.action_executor import ActionExecutor
from utils.breakers import CircuitBreakerManager
from utils.config import HedgeConfig, ValidationError
from utils.matsu_reporter import MatsuReporter
from pools import jlp, alp

logger = logging.getLogger(__name__)


class HedgeEngine:
    def __init__(self, config_path: str = "config.json"):
        self.config_path = Path(config_path)

        # ä½¿ç”¨ Pydantic é…ç½®åŠ è½½ï¼ˆè‡ªåŠ¨ä»ç¯å¢ƒå˜é‡å’Œ .env æ–‡ä»¶è¯»å–ï¼‰
        try:
            self.validated_config = HedgeConfig()
            self.config = self.validated_config.to_dict()  # å…¼å®¹æ—§ä»£ç 
            logger.info(self.validated_config.get_summary())
        except ValidationError as e:
            logger.critical(f"Configuration validation failed: {e}")
            raise InvalidConfigError("config", str(e), "Valid configuration required")

        # åˆå§‹åŒ–çŠ¶æ€ç®¡ç†å™¨ï¼ˆå†…å­˜æ¨¡å¼ï¼‰
        self.state_manager = StateManager()

        # åˆå§‹åŒ–ç†”æ–­å™¨ç®¡ç†å™¨
        self.circuit_manager = CircuitBreakerManager()

        # åˆå§‹åŒ–äº¤æ˜“æ‰€å’Œé€šçŸ¥å™¨
        self.exchange = create_exchange(self.config["exchange"])
        self.notifier = Notifier(self.config["pushover"])

        # åˆå§‹åŒ–Matsuç›‘æ§ä¸ŠæŠ¥å™¨ï¼ˆå¯é€‰æ’ä»¶ï¼‰
        self.matsu_reporter = self._initialize_matsu_reporter()

        # åˆå§‹åŒ–å†³ç­–å¼•æ“
        self.decision_engine = DecisionEngine(self.config, self.state_manager)

        # åˆå§‹åŒ–æ“ä½œæ‰§è¡Œå™¨
        self.action_executor = ActionExecutor(
            exchange=self.exchange,
            state_manager=self.state_manager,
            notifier=self.notifier,
            metrics_collector=None,  # Metricså·²ç§»é™¤
            circuit_manager=self.circuit_manager
        )

        # åˆ›å»ºå®Œæ•´çš„æ•°æ®å¤„ç†ç®¡é“
        self.pipeline = self._create_full_pipeline()

    def _initialize_matsu_reporter(self):
        """åˆå§‹åŒ–Matsuç›‘æ§ä¸ŠæŠ¥å™¨ï¼ˆå¯é€‰ï¼‰"""
        matsu_config = self.config.get("matsu", {})

        if not matsu_config.get("enabled", False):
            logger.debug("Matsu reporter disabled")
            return None

        auth_token = matsu_config.get("auth_token", "")
        if not auth_token:
            logger.warning("Matsu reporter enabled but auth_token is empty")
            return None

        try:
            api_url = matsu_config.get("api_endpoint", "https://distill.baa.one/api/hedge-data")
            pool_name = matsu_config.get("pool_name", "xLP")
            timeout = matsu_config.get("timeout", 10)

            reporter = MatsuReporter(
                api_url=api_url,
                auth_token=auth_token,
                enabled=True,
                timeout=timeout,
                pool_name=pool_name
            )
            logger.info(f"âœ… Matsu reporter enabled: {pool_name}")
            return reporter
        except Exception as e:
            logger.error(f"Failed to initialize Matsu reporter: {e}")
            return None

    def _create_full_pipeline(self):
        """åˆ›å»ºå®Œæ•´çš„æ•°æ®å¤„ç†ç®¡é“"""
        # å‡†å¤‡æ± å­è®¡ç®—å™¨
        pool_calculators = {
            "jlp": jlp.calculate_hedge,
            "alp": alp.calculate_hedge
        }

        # ä½¿ç”¨å·¥å‚å‡½æ•°åˆ›å»ºç®¡é“ï¼ˆåŒ…å«å¯é€‰çš„Matsuä¸ŠæŠ¥ä¸­é—´ä»¶ï¼‰
        return create_hedge_pipeline(
            pool_calculators=pool_calculators,
            exchange=self.exchange,
            state_manager=self.state_manager,
            offset_calculator=calculate_offset_and_cost,
            decision_engine=self.decision_engine,
            action_executor=self.action_executor,
            cooldown_minutes=self.config.get("cooldown_after_fill_minutes", 5),
            matsu_reporter=self.matsu_reporter  # ğŸ†• å¯é€‰çš„Matsuä¸ŠæŠ¥æ’ä»¶
        )

    async def run_once_pipeline(self):
        """ä½¿ç”¨ç®¡é“æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„å¯¹å†²æ£€æŸ¥å¾ªç¯"""
        start_time = time.time()
        logger.info(f"{'='*70}")
        logger.info(f"ğŸš€ HEDGE ENGINE PIPELINE - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"{'='*70}")

        try:
            # å‡†å¤‡ç®¡é“ä¸Šä¸‹æ–‡
            context = PipelineContext(
                config={
                    **self.config,
                    "jlp": {"amount": self.config["jlp_amount"]},
                    "alp": {"amount": self.config["alp_amount"]}
                }
            )

            # ä¸º reporting æä¾› state_manager
            context.metadata["state_manager"] = self.state_manager

            # æ‰§è¡Œç®¡é“
            context = await self.pipeline.execute(context)

            # å¤„ç†ç®¡é“ç»“æœ
            if context.results:
                success_count = sum(1 for r in context.results if r.status.value == "success")
                failed_count = sum(1 for r in context.results if r.status.value == "failed")

                # æ£€æŸ¥æ˜¯å¦æœ‰å…³é”®æ­¥éª¤å¤±è´¥
                critical_failures = [
                    r for r in context.results
                    if r.status.value == "failed" and r.name in ["FetchPoolData", "CalculateIdealHedges"]
                ]

                if critical_failures:
                    logger.error(f"âŒ Critical steps failed: {[f.name for f in critical_failures]}")
                    raise HedgeEngineError("Critical pipeline steps failed")

                # ç”Ÿæˆæœ€ç»ˆæ‘˜è¦æŠ¥å‘Š
                logger.info("=" * 70)
                logger.info("ğŸ“Š PIPELINE EXECUTION SUMMARY")
                logger.info("=" * 70)

                # æ˜¾ç¤ºå„æ­¥éª¤çŠ¶æ€
                logger.info("ğŸ“ˆ Step Results:")
                for result in context.results:
                    status_icon = "âœ…" if result.status.value == "success" else "âŒ"
                    logger.info(f"  {status_icon} {result.name}: {result.status.value} ({result.duration:.2f}s)")

                # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
                if context.offsets:
                    logger.info("ğŸ’° Position Summary:")
                    total_offset_usd = 0
                    for symbol, (offset, cost_basis) in context.offsets.items():
                        if symbol in context.prices:
                            offset_usd = abs(offset) * context.prices[symbol]
                            total_offset_usd += offset_usd
                            status = "ğŸ”´ LONG" if offset > 0 else ("ğŸŸ¢ SHORT" if offset < 0 else "âœ… BALANCED")
                            logger.info(f"  â€¢ {symbol}: {status} ${offset_usd:.2f} (Offset: {offset:+.4f})")
                    logger.info(f"  ğŸ“Š Total Exposure: ${total_offset_usd:.2f}")

                # æ˜¾ç¤ºæ‰§è¡Œç»“æœ
                if context.metadata.get("execution_results"):
                    exec_results = context.metadata["execution_results"]
                    exec_success = sum(1 for r in exec_results if r.success)
                    logger.info(f"âš¡ Actions Executed: {exec_success}/{len(exec_results)} successful")

                logger.info(f"â±ï¸ Total Time: {success_count} steps completed in {time.time() - start_time:.2f}s")

            # æ›´æ–°å…ƒæ•°æ®
            await self.state_manager.update_metadata({
                "last_check": datetime.now().isoformat(),
                "total_runs": (await self.state_manager.get_metadata()).get("total_runs", 0) + 1
            })

            # æ¸…ç†è¶…æ—¶çš„è®¢å•ç›‘æ§
            await self.state_manager.cleanup_stale_orders()

            # è®°å½•å¤„ç†æ—¶é—´
            processing_time = time.time() - start_time

            logger.info("=" * 70)
            logger.info(f"âœ… PIPELINE COMPLETED - Duration: {processing_time:.2f}s")
            logger.info("=" * 70)

        except Exception as e:
            logger.error(f"Pipeline execution error: {e}")

            # è®°å½•æœ€åçš„é”™è¯¯
            await self.state_manager.update_metadata({
                "last_error": str(e),
                "last_error_time": datetime.now().isoformat()
            })
            raise

    async def run_once(self):
        """æ‰§è¡Œä¸€æ¬¡æ£€æŸ¥å¾ªç¯ - ä½¿ç”¨æ•°æ®ç®¡é“æ¶æ„"""
        return await self.run_once_pipeline()


async def main():
    """æµ‹è¯•ä¸»å‡½æ•°"""
    engine = HedgeEngine()
    await engine.run_once()


if __name__ == "__main__":
    asyncio.run(main())
