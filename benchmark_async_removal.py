#!/usr/bin/env python3
"""
Async ç§»é™¤æ€§èƒ½ Benchmark

å¯¹æ¯”ï¼šç§»é™¤ä¸å¿…è¦çš„ async/await åçš„æ€§èƒ½æå‡
- MetricsCollector: async â†’ åŒæ­¥
- AuditLog: async â†’ åŒæ­¥
"""

import sys
import time
import asyncio
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent / 'src'))

from plugins.metrics import MetricsCollector
from plugins.audit_log import AuditLog
from core.decision_logic import Decision


def benchmark_metrics_sync(iterations=10000):
    """Benchmark: MetricsCollector (åŒæ­¥ç‰ˆæœ¬)"""
    print("\n" + "="*70)
    print("ğŸ“Š Benchmark 1: MetricsCollector (åŒæ­¥ç‰ˆæœ¬)")
    print("="*70)

    metrics = MetricsCollector()

    start_time = time.perf_counter()

    for i in range(iterations):
        decision = Decision(action="place_order", reason="test")
        metrics.record_decision("SOL", decision)

        if i % 2 == 0:
            result = {"success": True}
            metrics.record_action("SOL", "place_order", result)

    elapsed = time.perf_counter() - start_time
    ops_per_sec = iterations / elapsed

    print(f"âœ… å®Œæˆ {iterations:,} æ¬¡æ“ä½œ")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.4f}s")
    print(f"ğŸš€ ååé‡: {ops_per_sec:,.0f} ops/s")

    return elapsed, ops_per_sec


async def benchmark_metrics_async_wrapped(iterations=10000):
    """Benchmark: MetricsCollector åœ¨ async ä¸Šä¸‹æ–‡ä¸­è°ƒç”¨ï¼ˆæ¨¡æ‹Ÿæ—§ç‰ˆæœ¬ï¼‰"""
    print("\n" + "="*70)
    print("ğŸ“Š Benchmark 2: MetricsCollector åœ¨ async ä¸Šä¸‹æ–‡ï¼ˆæ¨¡æ‹Ÿï¼‰")
    print("="*70)

    metrics = MetricsCollector()

    start_time = time.perf_counter()

    for i in range(iterations):
        decision = Decision(action="place_order", reason="test")
        # æ¨¡æ‹Ÿæ—§ç‰ˆæœ¬ï¼šåœ¨ async ä¸Šä¸‹æ–‡ä¸­è°ƒç”¨ï¼ˆè™½ç„¶æ˜¯åŒæ­¥çš„ï¼‰
        await asyncio.sleep(0)  # æ¨¡æ‹Ÿ event loop åˆ‡æ¢å¼€é”€
        metrics.record_decision("SOL", decision)

        if i % 2 == 0:
            result = {"success": True}
            await asyncio.sleep(0)
            metrics.record_action("SOL", "place_order", result)

    elapsed = time.perf_counter() - start_time
    ops_per_sec = iterations / elapsed

    print(f"âœ… å®Œæˆ {iterations:,} æ¬¡æ“ä½œ")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.4f}s")
    print(f"ğŸš€ ååé‡: {ops_per_sec:,.0f} ops/s")
    print(f"âš ï¸  æ³¨æ„ï¼šåŒ…å« event loop åˆ‡æ¢å¼€é”€")

    return elapsed, ops_per_sec


def benchmark_audit_log_sync(iterations=5000):
    """Benchmark: AuditLog (åŒæ­¥ç‰ˆæœ¬)"""
    print("\n" + "="*70)
    print("ğŸ“Š Benchmark 3: AuditLog (åŒæ­¥ç‰ˆæœ¬)")
    print("="*70)

    import tempfile
    import os

    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.jsonl') as f:
        log_file = f.name

    try:
        audit = AuditLog(log_file=log_file, enabled=True)

        start_time = time.perf_counter()

        for i in range(iterations):
            decision = Decision(action="place_order", reason="test")
            audit.log_decision("SOL", decision)

            if i % 2 == 0:
                result = {"success": True, "order_id": f"order-{i}"}
                audit.log_action("SOL", "place_order", result)

        elapsed = time.perf_counter() - start_time
        ops_per_sec = iterations / elapsed

        print(f"âœ… å®Œæˆ {iterations:,} æ¬¡æ“ä½œ (å«æ–‡ä»¶å†™å…¥)")
        print(f"â±ï¸  è€—æ—¶: {elapsed:.4f}s")
        print(f"ğŸš€ ååé‡: {ops_per_sec:,.0f} ops/s")

        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(log_file) / 1024
        print(f"ğŸ“„ æ—¥å¿—æ–‡ä»¶å¤§å°: {file_size:.2f} KB")

        return elapsed, ops_per_sec
    finally:
        os.unlink(log_file)


def benchmark_combined_sync(iterations=10000):
    """Benchmark: ç»„åˆåœºæ™¯ï¼ˆæ¨¡æ‹ŸçœŸå®ä½¿ç”¨ï¼‰"""
    print("\n" + "="*70)
    print("ğŸ“Š Benchmark 4: ç»„åˆåœºæ™¯ (Metrics + AuditLog)")
    print("="*70)

    metrics = MetricsCollector()
    audit = AuditLog(enabled=False)  # ä¸å†™æ–‡ä»¶ï¼Œåªæµ‹å†…å­˜æ“ä½œ

    start_time = time.perf_counter()

    for i in range(iterations):
        symbol = "SOL" if i % 2 == 0 else "BTC"
        decision = Decision(action="place_order", reason="test")

        # æ¨¡æ‹Ÿå›è°ƒï¼šåŒæ—¶è°ƒç”¨
        audit.log_decision(symbol, decision)
        metrics.record_decision(symbol, decision)

        if i % 3 == 0:
            result = {"success": True, "order_id": f"order-{i}"}
            audit.log_action(symbol, "place_order", result)
            metrics.record_action(symbol, "place_order", result)

    elapsed = time.perf_counter() - start_time
    ops_per_sec = iterations / elapsed

    print(f"âœ… å®Œæˆ {iterations:,} æ¬¡æ“ä½œ")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.4f}s")
    print(f"ğŸš€ ååé‡: {ops_per_sec:,.0f} ops/s")

    # æ˜¾ç¤º metrics ç»Ÿè®¡
    summary = metrics.get_summary()
    print(f"ğŸ“ˆ Metrics: {summary['metrics'].get('decisions_total', 0)} decisions, "
          f"{summary['metrics'].get('actions_total', 0)} actions")

    return elapsed, ops_per_sec


def main():
    """è¿è¡Œæ‰€æœ‰ benchmark"""
    print("\n" + "="*70)
    print("ğŸ”¥ Async ç§»é™¤æ€§èƒ½ Benchmark - P0.2 ä¼˜åŒ–")
    print("="*70)
    print()
    print("ä¼˜åŒ–äº®ç‚¹ï¼š")
    print("  âœ… MetricsCollector: async â†’ åŒæ­¥")
    print("  âœ… AuditLog: async â†’ åŒæ­¥")
    print("  âœ… å»æ‰ asyncio.Lock â†’ threading.Lock")
    print("  âœ… å»æ‰ä¸å¿…è¦çš„ event loop å¼€é”€")
    print()

    results = {}

    # Benchmark 1: MetricsCollector åŒæ­¥
    elapsed1, ops1 = benchmark_metrics_sync(iterations=10000)
    results['metrics_sync'] = ops1

    # Benchmark 2: MetricsCollector async wrapped (æ¨¡æ‹Ÿ)
    elapsed2, ops2 = asyncio.run(benchmark_metrics_async_wrapped(iterations=10000))
    results['metrics_async'] = ops2

    # Benchmark 3: AuditLog åŒæ­¥
    elapsed3, ops3 = benchmark_audit_log_sync(iterations=5000)
    results['audit_sync'] = ops3

    # Benchmark 4: ç»„åˆåœºæ™¯
    elapsed4, ops4 = benchmark_combined_sync(iterations=10000)
    results['combined'] = ops4

    # æ€»ç»“
    print("\n" + "="*70)
    print("ğŸ“ˆ æ€§èƒ½æ€»ç»“")
    print("="*70)
    print(f"  MetricsCollector (åŒæ­¥):   {results['metrics_sync']:>12,.0f} ops/s")
    print(f"  MetricsCollector (asyncåŒ…è£…): {results['metrics_async']:>12,.0f} ops/s")
    print(f"  AuditLog (åŒæ­¥):            {results['audit_sync']:>12,.0f} ops/s")
    print(f"  ç»„åˆåœºæ™¯:                   {results['combined']:>12,.0f} ops/s")
    print()

    # è®¡ç®—æå‡
    if results['metrics_async'] > 0:
        improvement = (results['metrics_sync'] / results['metrics_async'] - 1) * 100
        print(f"âš¡ ç›¸æ¯” async åŒ…è£…æå‡: {improvement:.1f}%")
    print()
    print("ğŸ¯ å®é™…æ•ˆæœï¼š")
    print("  - å»æ‰ async/await å¼€é”€")
    print("  - threading.Lock æ¯” asyncio.Lock æ›´å¿«")
    print("  - ä»£ç æ›´ç®€æ´ï¼Œæ›´æ˜“ç»´æŠ¤")
    print()


if __name__ == "__main__":
    main()
